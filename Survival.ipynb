{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPaR+kzFJFNboqh9v+4Iyqf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/douglasmasho/MedAlgo/blob/main/Survival.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAWdnGi2HVGF",
        "outputId": "0b201726-14b3-44b3-ea5e-41ba43af351c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/BRATS/MICCAI_BraTS_2019_Data_Training/HGG\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/BRATS/MICCAI_BraTS_2019_Data_Training'\n",
        "\n",
        "survival_data = os.path.join(data_dir, \"survival_data.csv\")\n",
        "hgg_images = os.path.join(data_dir, \"HGG\")\n",
        "lgg_images = os.path.join(data_dir, \"LGG\")\n",
        "\n",
        "print(hgg_images)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZJ4n9xCThDt",
        "outputId": "6e4ed667-c041-448a-8448-f3f284890fc8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.3.2\n",
            "    Uninstalling scikit-learn-1.3.2:\n",
            "      Successfully uninstalled scikit-learn-1.3.2\n",
            "Successfully installed scikit-learn-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.data import Dataset\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def create_2d_cnn_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1)  # Change to Dense(num_classes, activation='softmax') for multi-class classification\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "def data_generator(X, ages, y, batch_size):\n",
        "    def generator():\n",
        "        for i in range(len(X)):\n",
        "            yield (X[i], np.array([ages[i]])), y[i]\n",
        "\n",
        "    dataset = Dataset.from_generator(generator,\n",
        "                                     output_signature=(\n",
        "                                         (tf.TensorSpec(shape=(64, 64, 1), dtype=tf.float32),\n",
        "                                          tf.TensorSpec(shape=(1,), dtype=tf.float32)),\n",
        "                                         tf.TensorSpec(shape=(), dtype=tf.float32)))\n",
        "    dataset = dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE).repeat()\n",
        "    return dataset\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # Example data loading function (Replace with actual data loading)\n",
        "        def get_data():\n",
        "            # Dummy data for example purposes\n",
        "            X = np.random.rand(32860, 64, 64)  # Replace with actual MRI data loading\n",
        "            y = np.random.rand(32860)  # Replace with actual labels\n",
        "            ages = np.random.rand(32860)  # Replace with actual age data\n",
        "            return X, y, ages\n",
        "\n",
        "        X, y, ages = get_data()\n",
        "\n",
        "        if X is None:\n",
        "            print(\"Exiting due to lack of valid data.\")\n",
        "        else:\n",
        "            print(f\"Loaded {len(X)} samples\")\n",
        "\n",
        "            # Resize X to add channel dimension\n",
        "            X = np.expand_dims(X, axis=-1)  # Add channel dimension for grayscale images\n",
        "\n",
        "            # Split the data\n",
        "            X_train, X_test, y_train, y_test, ages_train, ages_test = train_test_split(X, y, ages, test_size=0.2, random_state=42)\n",
        "\n",
        "            # Print dataset sizes\n",
        "            print(f\"Training set size: {len(X_train)}\")\n",
        "            print(f\"Test set size: {len(X_test)}\")\n",
        "\n",
        "            # Create and compile the model\n",
        "            model = create_2d_cnn_model((64, 64, 1))\n",
        "\n",
        "            # Create data generators\n",
        "            batch_size = 4\n",
        "            train_gen = data_generator(X_train, ages_train, y_train, batch_size)\n",
        "            val_gen = data_generator(X_test, ages_test, y_test, batch_size)\n",
        "\n",
        "            # Check if generators are not None\n",
        "            if train_gen is None or val_gen is None:\n",
        "                raise ValueError(\"One or both data generators are not initialized properly.\")\n",
        "\n",
        "            # Train the model\n",
        "            history = model.fit(\n",
        "                train_gen,\n",
        "                validation_data=val_gen,\n",
        "                epochs=10,\n",
        "                steps_per_epoch=len(X_train) // batch_size,\n",
        "                validation_steps=len(X_test) // batch_size\n",
        "            )\n",
        "\n",
        "            # Evaluate the model\n",
        "            test_loss, test_mae = model.evaluate(val_gen)\n",
        "            print(f\"Test MAE: {test_mae}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "4oCBTf4zQPIY",
        "outputId": "17856b31-11c5-42b6-fb60-1e43714c368e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotADirectoryError",
          "evalue": "[Errno 20] Not a directory: '/content/drive/MyDrive/BRATS/MICCAI_BraTS_2019_Data_Training/name_mapping.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-65ff0fdecee4>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Load and split data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mfile_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mfile_paths_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_paths_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-65ff0fdecee4>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mlabel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mfile_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/content/drive/MyDrive/BRATS/MICCAI_BraTS_2019_Data_Training/name_mapping.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install monai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZIZFw5WOpf2",
        "outputId": "e5a3b82e-279c-4c4a-8fa1-99241833cceb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting monai\n",
            "  Downloading monai-1.3.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
            "Downloading monai-1.3.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: monai\n",
            "Successfully installed monai-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "# Custom function to load .nii files and convert to NumPy arrays\n",
        "def load_nifti(file_path):\n",
        "    img = nib.load(file_path)\n",
        "    return img.get_fdata()\n",
        "\n",
        "# Paths to your data\n",
        "data_dir_hgg = '/content/drive/MyDrive/BRATS/MICCAI_BraTS_2019_Data_Training/HGG'\n",
        "data_dir_lgg = '/content/drive/MyDrive/BRATS/MICCAI_BraTS_2019_Data_Training/LGG'\n",
        "survival_data_path = '/content/drive/MyDrive/BRATS/MICCAI_BraTS_2019_Data_Training/survival_data.csv'\n",
        "\n",
        "# Load survival data\n",
        "survival_data = pd.read_csv(survival_data_path)\n",
        "\n",
        "# Extract BraTS19ID from survival data\n",
        "ids = survival_data['BraTS19ID'].tolist()\n",
        "labels = survival_data['Survival'].tolist()  # Assuming survival is the target label\n",
        "\n",
        "file_paths = []\n",
        "labels_list = []\n",
        "\n",
        "# Function to process data\n",
        "def process_data(data_dir, label):\n",
        "    for subject_dir in os.listdir(data_dir):\n",
        "        subject_path = os.path.join(data_dir, subject_dir)\n",
        "        if os.path.isdir(subject_path):\n",
        "            t1ce_file = None\n",
        "            for file_name in os.listdir(subject_path):\n",
        "                if file_name.endswith('t1ce.nii'):\n",
        "                    t1ce_file = os.path.join(subject_path, file_name)\n",
        "                    break\n",
        "            if t1ce_file and subject_dir in ids:\n",
        "                file_paths.append(t1ce_file)\n",
        "                labels_list.append(label)\n",
        "\n",
        "# Process HGG and LGG directories\n",
        "process_data(data_dir_hgg, 1)  # Assuming 1 represents HGG\n",
        "process_data(data_dir_lgg, 0)  # Assuming 0 represents LGG\n",
        "\n",
        "# Check if data is loaded correctly\n",
        "if len(file_paths) == 0 or len(labels_list) == 0:\n",
        "    raise ValueError(\"No data found. Check if file paths and labels are correctly processed.\")\n",
        "\n",
        "# Split data\n",
        "file_paths_train, file_paths_test, labels_train, labels_test = train_test_split(file_paths, labels_list, test_size=0.2, random_state=42)\n",
        "\n",
        "# Custom dataset class\n",
        "class NiftiDataset(Dataset):\n",
        "    def __init__(self, file_paths, labels, transform=None):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.file_paths[idx]\n",
        "        image = load_nifti(img_path)\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Add channel dimension if missing\n",
        "        if image.ndim == 3:\n",
        "            image = np.expand_dims(image, axis=0)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return {'image': image, 'label': torch.tensor(label, dtype=torch.float32)}\n",
        "\n",
        "# Define transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64, 64)),  # Resize to smaller size\n",
        "    transforms.ToTensor()  # Convert to tensor\n",
        "])\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_ds = NiftiDataset(file_paths_train, labels_train, transform=transform)\n",
        "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=4, pin_memory=False)\n",
        "\n",
        "val_ds = NiftiDataset(file_paths_test, labels_test, transform=transform)\n",
        "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, pin_memory=False)\n",
        "\n",
        "# Define a simple model (you can use a more complex model as needed)\n",
        "class SimpleCNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv3d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv3d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = torch.nn.Linear(64 * 16 * 16 * 16, 128)  # Adjusted for smaller image size\n",
        "        self.fc2 = torch.nn.Linear(128, 1)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.pool = torch.nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 16 * 16 * 16)  # Adjusted for smaller image size\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = SimpleCNN().cuda()\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Training loop with mixed precision\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch in train_loader:\n",
        "        images, labels = batch[\"image\"].cuda(), batch[\"label\"].cuda()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs.squeeze(), labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            images, labels = batch[\"image\"].cuda(), batch[\"label\"].cuda()\n",
        "            with autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs.squeeze(), labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Validation Loss: {val_loss / len(val_loader)}\")\n",
        "\n",
        "    # Clear memory\n",
        "    del batch\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "ziQEONyrQ61M",
        "outputId": "6c432c20-0e5f-46e9-dff6-13e2422739db"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "If size is a sequence, it should have 1 or 2 values",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-827eb88d6f66>\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# Define transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m transform = transforms.Compose([\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Resize to smaller size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m ])\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Size should be int or sequence. Got {type(size)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"If size is a sequence, it should have 1 or 2 values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: If size is a sequence, it should have 1 or 2 values"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load survival data\n",
        "survival_data = pd.read_csv(survival_data_file)\n",
        "\n",
        "# Display the column names\n",
        "print(survival_data.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14NUFPz3RNty",
        "outputId": "11950b17-dbc2-4754-adb8-5a37e6f306cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['BraTS19ID', 'Age', 'Survival', 'ResectionStatus'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from sklearn.model_selection import train_test_split\n",
        "from monai.transforms import Compose, LoadImage, ScaleIntensity, Resize, ToTensor\n",
        "\n",
        "# Custom function to load .nii files and convert to NumPy arrays\n",
        "def load_nifti(file_path):\n",
        "    img = nib.load(file_path)\n",
        "    return img.get_fdata()\n",
        "\n",
        "# Paths to your data\n",
        "data_dir_hgg = '/content/drive/MyDrive/BRATS/MICCAI_BraTS_2019_Data_Training/HGG'\n",
        "data_dir_lgg = '/content/drive/MyDrive/BRATS/MICCAI_BraTS_2019_Data_Training/LGG'\n",
        "survival_data_path = '/content/drive/MyDrive/BRATS/MICCAI_BraTS_2019_Data_Training/survival_data.csv'\n",
        "\n",
        "# Load survival data\n",
        "survival_data = pd.read_csv(survival_data_path)\n",
        "\n",
        "# Extract BraTS19ID from survival data\n",
        "ids = survival_data['BraTS19ID'].tolist()\n",
        "labels = survival_data['Survival'].tolist()  # Assuming survival is the target label\n",
        "\n",
        "file_paths = []\n",
        "labels_list = []\n",
        "\n",
        "# Function to process data\n",
        "def process_data(data_dir, label):\n",
        "    for subject_dir in os.listdir(data_dir):\n",
        "        subject_path = os.path.join(data_dir, subject_dir)\n",
        "        if os.path.isdir(subject_path):\n",
        "            t1ce_file = None\n",
        "            for file_name in os.listdir(subject_path):\n",
        "                if file_name.endswith('t1ce.nii'):\n",
        "                    t1ce_file = os.path.join(subject_path, file_name)\n",
        "                    break\n",
        "            if t1ce_file and subject_dir in ids:\n",
        "                file_paths.append(t1ce_file)\n",
        "                labels_list.append(label)\n",
        "\n",
        "# Process HGG and LGG directories\n",
        "process_data(data_dir_hgg, 1)  # Assuming 1 represents HGG\n",
        "process_data(data_dir_lgg, 0)  # Assuming 0 represents LGG\n",
        "\n",
        "# Check if data is loaded correctly\n",
        "if len(file_paths) == 0 or len(labels_list) == 0:\n",
        "    raise ValueError(\"No data found. Check if file paths and labels are correctly processed.\")\n",
        "\n",
        "# Split data\n",
        "file_paths_train, file_paths_test, labels_train, labels_test = train_test_split(file_paths, labels_list, test_size=0.2, random_state=42)\n",
        "\n",
        "# Custom dataset class\n",
        "class NiftiDataset(Dataset):\n",
        "    def __init__(self, file_paths, labels, transform=None):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.file_paths[idx]\n",
        "        image = load_nifti(img_path)\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Add channel dimension if missing\n",
        "        if image.ndim == 3:\n",
        "            image = np.expand_dims(image, axis=0)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return {'image': image, 'label': torch.tensor(label, dtype=torch.float32).unsqueeze(0)}  # Ensure label is of shape [1]\n",
        "\n",
        "# Define transforms\n",
        "transform = Compose([\n",
        "    Resize((64, 64, 64)),  # Resize images to a smaller size\n",
        "    ScaleIntensity(),  # Scale image intensity\n",
        "    ToTensor()  # Convert to tensor\n",
        "])\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_ds = NiftiDataset(file_paths_train, labels_train, transform=transform)\n",
        "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=2)  # Adjust num_workers as needed\n",
        "\n",
        "val_ds = NiftiDataset(file_paths_test, labels_test, transform=transform)\n",
        "val_loader = DataLoader(val_ds, batch_size=2, num_workers=2)  # Adjust num_workers as needed\n",
        "\n",
        "# Define a simple model (you can use a more complex model as needed)\n",
        "class SimpleCNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv3d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv3d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = torch.nn.Linear(64 * 16 * 16 * 16, 128)  # Adjusted for smaller image size\n",
        "        self.fc2 = torch.nn.Linear(128, 1)  # Single output unit\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.pool = torch.nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 16 * 16 * 16)  # Adjusted for smaller image size\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)  # Output logits\n",
        "        return x\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = SimpleCNN().cuda()\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Training loop with mixed precision\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch in train_loader:\n",
        "        images, labels = batch[\"image\"].cuda(), batch[\"label\"].cuda()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs.squeeze(), labels.squeeze())  # Ensure both are squeezed to same shape\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            images, labels = batch[\"image\"].cuda(), batch[\"label\"].cuda()\n",
        "            with autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs.squeeze(), labels.squeeze())  # Ensure both are squeezed to same shape\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Validation Loss: {val_loss / len(val_loader)}\")\n",
        "\n",
        "    # Clear memory\n",
        "    del batch\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORfvh2Y-RObO",
        "outputId": "4e57988d-a791-4a0f-e091-0bef615e308a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-1276477849b7>:118: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "<ipython-input-4-1276477849b7>:128: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.011005751862149336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-1276477849b7>:146: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Validation Loss: 1.6142662719029734e-11\n",
            "Epoch 2, Loss: 1.7220227325542622e-11\n",
            "Epoch 2, Validation Loss: 1.6132923147433927e-11\n",
            "Epoch 3, Loss: 1.720666749722317e-11\n",
            "Epoch 3, Validation Loss: 1.6132923147433927e-11\n",
            "Epoch 4, Loss: 1.7207559254161606e-11\n",
            "Epoch 4, Validation Loss: 1.6132923147433927e-11\n",
            "Epoch 5, Loss: 1.7467367286261578e-11\n",
            "Epoch 5, Validation Loss: 1.6132923147433927e-11\n",
            "Epoch 6, Loss: 1.7241933911015e-11\n",
            "Epoch 6, Validation Loss: 1.6132923147433927e-11\n",
            "Epoch 7, Loss: 1.720868684566197e-11\n",
            "Epoch 7, Validation Loss: 1.6132923147433927e-11\n",
            "Epoch 8, Loss: 1.7206667627014682e-11\n",
            "Epoch 8, Validation Loss: 1.6132923147433927e-11\n",
            "Epoch 9, Loss: 1.7207177215848904e-11\n",
            "Epoch 9, Validation Loss: 1.6132923147433927e-11\n",
            "Epoch 10, Loss: 1.7207117237315595e-11\n",
            "Epoch 10, Validation Loss: 1.6132923147433927e-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import os\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Simplified Data Generator\n",
        "class MRIDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, image_dirs, survival_data, batch_size=16, image_shape=(128, 128, 1), shuffle=True):\n",
        "        self.image_dirs = image_dirs\n",
        "        self.survival_data = survival_data\n",
        "        self.batch_size = batch_size\n",
        "        self.image_shape = image_shape\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = list(range(len(self.image_dirs)))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.image_dirs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        batch_dirs = [self.image_dirs[i] for i in batch_indices]\n",
        "        batch_images = []\n",
        "        batch_survival = []\n",
        "        batch_age = []\n",
        "\n",
        "        for img_dir in batch_dirs:\n",
        "            img, subject_id = self.load_image_from_folder(img_dir)\n",
        "            if img is not None:\n",
        "                batch_images.append(img)\n",
        "                survival, age = self.get_survival_data(subject_id)\n",
        "                batch_survival.append(survival)\n",
        "                batch_age.append(age)\n",
        "\n",
        "        batch_images = np.array(batch_images, dtype=np.float32)\n",
        "        batch_survival = np.array(batch_survival, dtype=np.float32)\n",
        "        batch_age = np.array(batch_age, dtype=np.float32)\n",
        "\n",
        "        # Ensure shapes are correct\n",
        "        batch_images = np.reshape(batch_images, (batch_images.shape[0], *self.image_shape))\n",
        "        batch_age = np.reshape(batch_age, (-1, 1))  # Ensure age is 2D\n",
        "\n",
        "        return {'image_input': batch_images, 'age_input': batch_age}, batch_survival\n",
        "\n",
        "    def load_image_from_folder(self, folder):\n",
        "        for file_name in os.listdir(folder):\n",
        "            if 't1ce.nii' in file_name:\n",
        "                img_path = os.path.join(folder, file_name)\n",
        "                img = nib.load(img_path).get_fdata()\n",
        "                img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
        "                img = img / np.max(img)  # Normalize\n",
        "                img = np.resize(img, self.image_shape)  # Resize to consistent shape\n",
        "                return img, os.path.basename(folder)\n",
        "        return None, None\n",
        "\n",
        "    def get_survival_data(self, subject_id):\n",
        "        survival = self.survival_data[self.survival_data['BraTS19ID'] == subject_id]['Survival']\n",
        "        age = self.survival_data[self.survival_data['BraTS19ID'] == subject_id]['Age']\n",
        "        return survival.values[0] if not survival.empty else np.nan, age.values[0] if not age.empty else 0\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "# Preprocess survival data\n",
        "def preprocess_survival(value):\n",
        "    if 'ALIVE' in str(value):\n",
        "        parts = str(value).split()\n",
        "        if len(parts) > 1 and parts[1].isdigit():\n",
        "            return float(parts[1])\n",
        "        else:\n",
        "            return 10000  # or another suitable high value\n",
        "    elif pd.isna(value) or str(value).strip() == '':\n",
        "        return np.nan  # or a placeholder like 0\n",
        "    else:\n",
        "        try:\n",
        "            return float(value)\n",
        "        except ValueError:\n",
        "            return np.nan  # Handle any unexpected formats\n",
        "\n",
        "# Load and preprocess survival data\n",
        "data_dir = '/content/drive/MyDrive/BRATS/MICCAI_BraTS_2019_Data_Training'\n",
        "survival_data_file = os.path.join(data_dir, 'survival_data.csv')\n",
        "survival_data = pd.read_csv(survival_data_file)\n",
        "\n",
        "# Preprocess survival data\n",
        "survival_data['Survival'] = survival_data['Survival'].apply(preprocess_survival)\n",
        "survival_data['Survival'].fillna(survival_data['Survival'].median(), inplace=True)\n",
        "survival_data['Age'] = StandardScaler().fit_transform(survival_data[['Age']])\n",
        "\n",
        "# Define directories\n",
        "hgg_images_dir = os.path.join(data_dir, 'HGG')\n",
        "lgg_images_dir = os.path.join(data_dir, 'LGG')\n",
        "\n",
        "# Prepare data\n",
        "hgg_dirs = [os.path.join(hgg_images_dir, d) for d in os.listdir(hgg_images_dir)]\n",
        "lgg_dirs = [os.path.join(lgg_images_dir, d) for d in os.listdir(lgg_images_dir)]\n",
        "all_dirs = hgg_dirs + lgg_dirs\n",
        "\n",
        "# Split data\n",
        "train_dirs, test_dirs = train_test_split(all_dirs, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create data generators\n",
        "train_generator = MRIDataGenerator(train_dirs, survival_data, batch_size=16)\n",
        "test_generator = MRIDataGenerator(test_dirs, survival_data, batch_size=16)\n",
        "\n",
        "# Define a simpler model for debugging\n",
        "image_input = Input(shape=(128, 128, 1), name='image_input')\n",
        "age_input = Input(shape=(1,), name='age_input')\n",
        "\n",
        "# Define CNN part for image processing\n",
        "x = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Concatenate image features with age\n",
        "x = Concatenate()([x, age_input])\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(1)(x)  # Output layer for regression\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=[image_input, age_input], outputs=output)\n",
        "model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=test_generator\n",
        ")\n",
        "\n",
        "# Evaluate model\n",
        "loss, mae = model.evaluate(test_generator)\n",
        "print(f\"Mean Absolute Error on test data: {mae}\")\n",
        "\n",
        "# Prediction function\n",
        "def predict_survival(image, age):\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    age = np.expand_dims(age, axis=0)\n",
        "    survival = model.predict({'image_input': image, 'age_input': age})\n",
        "    return survival\n",
        "\n",
        "# Example prediction\n",
        "example_batch = next(iter(test_generator))\n",
        "example_image = example_batch[0]['image_input'][0]\n",
        "predicted_survival = predict_survival(example_image, np.array([30]))  # Assuming age 30\n",
        "print(f\"Predicted survival: {predicted_survival}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lxclym4jXsOc",
        "outputId": "338fc560-67fe-41b4-c937-99665ef4fe2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ image_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_39 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m320\u001b[0m │ image_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_39          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_40 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_40          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_41 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_41          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_13 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ age_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_11            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25089\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ flatten_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ age_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │      \u001b[38;5;34m3,211,520\u001b[0m │ concatenate_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ image_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ image_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_39          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_40          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_41          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ age_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_11            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25089</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ age_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,211,520</span> │ concatenate_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,304,321\u001b[0m (12.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,304,321</span> (12.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,304,321\u001b[0m (12.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,304,321</span> (12.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Functional.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data_1:0\", shape=(None, 1), dtype=float32). Expected shape (None, 128, 128, 1), but input has incompatible shape (None, 1)\u001b[0m\n\nArguments received by Functional.call():\n  • inputs={'image_input': 'tf.Tensor(shape=(None, 128, 128, 1), dtype=float32)', 'age_input': 'tf.Tensor(shape=(None, 1), dtype=float32)'}\n  • training=True\n  • mask={'image_input': 'None', 'age_input': 'None'}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c298a0057e5f>\u001b[0m in \u001b[0;36m<cell line: 139>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36m_adjust_input_rank\u001b[0;34m(self, flat_inputs)\u001b[0m\n\u001b[1;32m    242\u001b[0m                     \u001b[0madjusted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0;34mf\"Invalid input shape for input {x}. Expected shape \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0;34mf\"{ref_shape}, but input has incompatible shape {x.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Functional.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data_1:0\", shape=(None, 1), dtype=float32). Expected shape (None, 128, 128, 1), but input has incompatible shape (None, 1)\u001b[0m\n\nArguments received by Functional.call():\n  • inputs={'image_input': 'tf.Tensor(shape=(None, 128, 128, 1), dtype=float32)', 'age_input': 'tf.Tensor(shape=(None, 1), dtype=float32)'}\n  • training=True\n  • mask={'image_input': 'None', 'age_input': 'None'}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define a minimal model\n",
        "def create_model():\n",
        "    image_input = Input(shape=(128, 128, 1), name='image_input')\n",
        "    age_input = Input(shape=(1,), name='age_input')\n",
        "\n",
        "    x = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Combine features\n",
        "    combined = Concatenate()([x, age_input])\n",
        "    x = Dense(64, activation='relu')(combined)\n",
        "    x = Dropout(0.5)(x)\n",
        "    output = Dense(1)(x)\n",
        "\n",
        "    model = Model(inputs=[image_input, age_input], outputs=output)\n",
        "    model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Dummy data generator to tf.data.Dataset\n",
        "def create_dataset(batch_size=16):\n",
        "    num_samples = 100\n",
        "    image_data = np.random.rand(num_samples, 128, 128, 1).astype(np.float32)\n",
        "    age_data = np.random.rand(num_samples, 1).astype(np.float32)\n",
        "    survival_data = np.random.rand(num_samples).astype(np.float32)\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(((image_data, age_data), survival_data))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "# Create and compile model\n",
        "model = create_model()\n",
        "model.summary()\n",
        "\n",
        "# Create dataset\n",
        "train_dataset = create_dataset()\n",
        "\n",
        "# Train the model\n",
        "try:\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        epochs=2,\n",
        "        steps_per_epoch=10\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(\"Error during training:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "nTaP9B-aYeof",
        "outputId": "94879225-4317-44f4-f284-9f46498f193f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_20\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_20\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ image_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_54 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m320\u001b[0m │ image_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_54          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_20 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127008\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ age_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_18            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127009\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ flatten_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ age_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │      \u001b[38;5;34m8,128,640\u001b[0m │ concatenate_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dropout_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ image_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ image_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_54          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127008</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ age_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_18            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127009</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ age_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,128,640</span> │ concatenate_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,129,025\u001b[0m (31.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,129,025</span> (31.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,129,025\u001b[0m (31.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,129,025</span> (31.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 139ms/step - loss: 398.3152 - mae: 10.7971\n",
            "Epoch 2/2\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3174 - mae: 0.9568 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2D9nEaloYfIZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}