{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOHtHN5oP7e/61xM8vGGx8+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/douglasmasho/MedAlgo/blob/main/TumorGrade2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jFt7NAQ-XIZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03efbab9-89ed-43b9-c0fc-b1b670337e33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install monai"
      ],
      "metadata": {
        "id": "ErkrL3UAY9SS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a1a6074-8101-4055-f102-74b29443af4b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting monai\n",
            "  Downloading monai-1.3.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9->monai)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
            "Downloading monai-1.3.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, monai\n",
            "Successfully installed monai-1.3.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "extract_dir = '/content/drive/MyDrive/BRATS'\n",
        "\n",
        "def find_nifti_files(root_dir, label):\n",
        "    \"\"\"Recursively find all .nii files in subdirectories and assign a label.\"\"\"\n",
        "    file_paths = []\n",
        "    for subdir, _, _ in os.walk(root_dir):\n",
        "        file_paths.extend(glob.glob(os.path.join(subdir, '*.nii')))\n",
        "    return file_paths, [label] * len(file_paths)\n",
        "\n",
        "# Define paths\n",
        "hgg_path = os.path.join(extract_dir, \"MICCAI_BraTS_2019_Data_Training\",'HGG')\n",
        "lgg_path = os.path.join(extract_dir, \"MICCAI_BraTS_2019_Data_Training\",'LGG')\n",
        "\n",
        "# Find all .nii files\n",
        "hgg_files, hgg_labels = find_nifti_files(hgg_path, 1)  # High-grade glioma\n",
        "lgg_files, lgg_labels = find_nifti_files(lgg_path, 0)  # Low-grade glioma\n",
        "\n",
        "print(f'HGG files: {len(hgg_files)}')\n",
        "print(f'LGG files: {len(lgg_files)}')\n",
        "\n",
        "# Combine and split data\n",
        "all_files = hgg_files + lgg_files\n",
        "all_labels = hgg_labels + lgg_labels\n",
        "\n",
        "print(f'All files: {len(all_files)}')\n",
        "print(f'All labels: {len(all_labels)}')\n",
        "\n",
        "# Ensure non-empty lists before splitting\n",
        "if len(all_files) == 0 or len(all_labels) == 0:\n",
        "    raise ValueError(\"The file paths or labels are empty. Check the directory and file extensions.\")\n",
        "\n",
        "train_files, val_files, train_labels, val_labels = train_test_split(\n",
        "    all_files, all_labels, test_size=0.2, stratify=all_labels, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "i9-oF4swXMKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import monai\n",
        "from monai.transforms import Compose, LoadImage, ScaleIntensity, EnsureChannelFirst, Resize, ToTensor\n",
        "from monai.data import Dataset, DataLoader\n",
        "\n",
        "# Define transformations\n",
        "transforms = Compose([\n",
        "    LoadImage(image_only=True),  # Load NIfTI image\n",
        "    ScaleIntensity(),            # Normalize intensity\n",
        "    EnsureChannelFirst(),        # Add channel dimension\n",
        "    Resize((128, 128, 128)),     # Resize to a fixed size\n",
        "    ToTensor()                   # Convert to tensor\n",
        "])\n",
        "\n",
        "# Create custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = image_path  # Load image directly\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return {'image': image, 'label': label}\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = CustomDataset(train_files, train_labels, transform=transforms)\n",
        "val_dataset = CustomDataset(val_files, val_labels, transform=transforms)\n",
        "\n",
        "batch_size = 4\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=2)\n"
      ],
      "metadata": {
        "id": "SEJA1KUHXRNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install monai\n"
      ],
      "metadata": {
        "id": "USj6JJ0Nx6UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from monai.networks.nets import DenseNet121\n",
        "from monai.transforms import Compose, LoadImage, ScaleIntensity, EnsureChannelFirst, Resize, RandAffine, RandRotate, RandZoom, ToTensor\n",
        "from monai.data import Dataset, DataLoader\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nibabel as nib\n",
        "\n",
        "extract_dir = '/content/drive/MyDrive/BRATS'\n",
        "\n",
        "# Define paths\n",
        "hgg_path = os.path.join(extract_dir, \"MICCAI_BraTS_2019_Data_Training\", 'HGG')\n",
        "lgg_path = os.path.join(extract_dir, \"MICCAI_BraTS_2019_Data_Training\", 'LGG')\n",
        "\n",
        "# Define a function to find all .nii files within each subject's directory\n",
        "def find_nifti_files(root_dir, label):\n",
        "    subject_dirs = [os.path.join(root_dir, d) for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
        "    file_paths = []\n",
        "    for subject_dir in subject_dirs:\n",
        "        nii_files = glob.glob(os.path.join(subject_dir, '*.nii'))\n",
        "        if nii_files:\n",
        "            file_paths.append(nii_files[0])  # Taking the first .nii file as an example\n",
        "    return file_paths, [label] * len(file_paths)\n",
        "\n",
        "# Find all .nii files\n",
        "hgg_files, hgg_labels = find_nifti_files(hgg_path, 1)\n",
        "lgg_files, lgg_labels = find_nifti_files(lgg_path, 0)\n",
        "\n",
        "all_files = hgg_files + lgg_files\n",
        "all_labels = hgg_labels + lgg_labels\n",
        "\n",
        "# Convert lists to numpy arrays for resampling\n",
        "all_files_np = np.array(all_files)\n",
        "all_labels_np = np.array(all_labels)\n",
        "\n",
        "# Oversample the minority class\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "resampled_files, resampled_labels = ros.fit_resample(all_files_np.reshape(-1, 1), all_labels_np)\n",
        "resampled_files = resampled_files.flatten()\n",
        "\n",
        "# Split resampled data\n",
        "train_files, val_files, train_labels, val_labels = train_test_split(\n",
        "    resampled_files, resampled_labels, test_size=0.2, stratify=resampled_labels, random_state=42\n",
        ")\n",
        "\n",
        "# Define transformations with augmentation\n",
        "transforms = Compose([\n",
        "    ScaleIntensity(),\n",
        "    Resize((128, 128)),\n",
        "    RandAffine(prob=0.5),\n",
        "    RandRotate(range_x=(0, 15), prob=0.5),\n",
        "    RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "# Create custom dataset class for 2D slices\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None, augment_minority=False):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.augment_minority = augment_minority\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Load the NIfTI file\n",
        "        img = nib.load(image_path).get_fdata()\n",
        "\n",
        "        # Choose a random slice along the axial plane (e.g., middle slice)\n",
        "        slice_index = img.shape[2] // 2\n",
        "        image_slice = img[:, :, slice_index]\n",
        "\n",
        "        # Add channel dimension for grayscale\n",
        "        image_slice = np.expand_dims(image_slice, axis=0)\n",
        "\n",
        "        if self.augment_minority and label == 0:\n",
        "            if self.transform:\n",
        "                image_slice = self.transform(image_slice)\n",
        "        else:\n",
        "            if self.transform:\n",
        "                image_slice = self.transform(image_slice)\n",
        "\n",
        "        return {'image': image_slice, 'label': label}\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "batch_size = 4\n",
        "train_dataset = CustomDataset(train_files, train_labels, transform=transforms, augment_minority=True)\n",
        "val_dataset = CustomDataset(val_files, val_labels, transform=transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=2)\n",
        "\n",
        "# Define the model for 2D input\n",
        "model = DenseNet121(spatial_dims=2, in_channels=1, out_channels=2)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Training loop\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        images = batch['image'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_accuracy = correct_predictions / total_predictions\n",
        "    print(f'Epoch {epoch + 1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
        "\n",
        "    # Validation step\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct_predictions = 0\n",
        "    val_total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            images = batch['image'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate validation accuracy\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_correct_predictions += (predicted == labels).sum().item()\n",
        "            val_total_predictions += labels.size(0)\n",
        "\n",
        "    val_epoch_loss = val_loss / len(val_loader)\n",
        "    val_epoch_accuracy = val_correct_predictions / val_total_predictions\n",
        "    print(f'Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_accuracy:.4f}')\n",
        "\n",
        "print('Training complete!')\n"
      ],
      "metadata": {
        "id": "6DQFZs9UXUfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed8d366a-308e-4ad9-8ca3-31eb7e15bdc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.5875, Accuracy: 0.6763\n",
            "Validation Loss: 0.5327, Validation Accuracy: 0.7692\n",
            "Epoch 2, Loss: 0.5655, Accuracy: 0.7198\n",
            "Validation Loss: 0.6284, Validation Accuracy: 0.7500\n",
            "Epoch 3, Loss: 0.5845, Accuracy: 0.6884\n",
            "Validation Loss: 0.5423, Validation Accuracy: 0.6827\n",
            "Epoch 4, Loss: 0.5300, Accuracy: 0.7246\n",
            "Validation Loss: 0.4841, Validation Accuracy: 0.7596\n",
            "Epoch 5, Loss: 0.5337, Accuracy: 0.7053\n",
            "Validation Loss: 0.5626, Validation Accuracy: 0.7308\n",
            "Epoch 6, Loss: 0.5423, Accuracy: 0.7464\n",
            "Validation Loss: 0.5111, Validation Accuracy: 0.7404\n",
            "Epoch 7, Loss: 0.5431, Accuracy: 0.7343\n",
            "Validation Loss: 0.4473, Validation Accuracy: 0.7885\n",
            "Epoch 8, Loss: 0.5077, Accuracy: 0.7536\n",
            "Validation Loss: 0.5631, Validation Accuracy: 0.6538\n",
            "Epoch 9, Loss: 0.4967, Accuracy: 0.7657\n",
            "Validation Loss: 0.4870, Validation Accuracy: 0.7981\n",
            "Epoch 10, Loss: 0.5184, Accuracy: 0.7367\n",
            "Validation Loss: 0.4671, Validation Accuracy: 0.7885\n",
            "Epoch 11, Loss: 0.5115, Accuracy: 0.7391\n",
            "Validation Loss: 0.4510, Validation Accuracy: 0.7500\n",
            "Epoch 12, Loss: 0.5569, Accuracy: 0.7319\n",
            "Validation Loss: 0.6976, Validation Accuracy: 0.7692\n",
            "Epoch 13, Loss: 0.5070, Accuracy: 0.7536\n",
            "Validation Loss: 0.5016, Validation Accuracy: 0.7596\n",
            "Epoch 14, Loss: 0.4755, Accuracy: 0.7826\n",
            "Validation Loss: 0.5039, Validation Accuracy: 0.7308\n",
            "Epoch 15, Loss: 0.4844, Accuracy: 0.7874\n",
            "Validation Loss: 0.4172, Validation Accuracy: 0.8173\n",
            "Epoch 16, Loss: 0.4587, Accuracy: 0.8019\n",
            "Validation Loss: 0.6923, Validation Accuracy: 0.7885\n",
            "Epoch 17, Loss: 0.4994, Accuracy: 0.7609\n",
            "Validation Loss: 0.5848, Validation Accuracy: 0.7692\n",
            "Epoch 18, Loss: 0.4473, Accuracy: 0.7971\n",
            "Validation Loss: 0.4939, Validation Accuracy: 0.8077\n",
            "Epoch 19, Loss: 0.4637, Accuracy: 0.7560\n",
            "Validation Loss: 0.5106, Validation Accuracy: 0.7500\n"
          ]
        }
      ]
    }
  ]
}